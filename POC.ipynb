{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\agent\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "class Generators:\n",
    "    def __init__(self, model=\"llama-3.3-70b-versatile\"):\n",
    "        # self.llm = Ollama(model=model, temperature=0)\n",
    "        self.llm = Groq(model=model, api_key=\"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\", temperature=0)\n",
    "\n",
    "    def get_llm(self):\n",
    "        return self.llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "session = dict()\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"useful tool to Multiply two numbers and returns the product\n",
    "    make sure that both numbers a, b are real numbers and if not try to convert them to real numbers\n",
    "    args:\n",
    "        a: float\n",
    "        b: float    \n",
    "    requires:\n",
    "        only_real_numbers\n",
    "    \"\"\"\n",
    "    return float(a) * float(b)\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"useful tool to Add two numbers and returns the sum, \n",
    "    make sure that both numbers a, b are real numbers and if not try to convert them to real numbers\n",
    "    args:\n",
    "        a: float\n",
    "        b: float    \n",
    "\n",
    "    requires:\n",
    "        only_real_numbers\n",
    "    \"\"\"\n",
    "    return float(a) + float(b)\n",
    "\n",
    "def only_real_numbers(a: float) -> float:\n",
    "    \"\"\" useful tool to verify if the number is real\"\"\"\n",
    "    try: \n",
    "        float(a)\n",
    "    except ValueError: \n",
    "        return f\"{a} is not a real number so try converting it to a float and try again\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent import FunctionCallingAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "real_number_tool = FunctionTool.from_defaults(fn=only_real_numbers)\n",
    "\n",
    "class AgentController:\n",
    "    def __init__(self):        \n",
    "        self.llm = Generators().get_llm()\n",
    "        self.system_prompt = \"\"\"\n",
    "                                You are a math expert. You will only use the tools available to you.\n",
    "                                IMPORTANT NOTE: You will ALWAYS evaluate the user's query and perfom query classification and provide three things:\n",
    "                                tool_used, reasoning, answer\n",
    "                                \n",
    "                                like this:\n",
    "\n",
    "                                Answer: answer\n",
    "                                Tool Used: tool_name\n",
    "                                Reasoning: reasoning for using the tool\n",
    "\n",
    "                                An example:\n",
    "\n",
    "                                Answer: 21.0\n",
    "                                Tool Used: multiply\n",
    "                                Reasoning: The tool was used to calculate the product of two numbers.\n",
    "                                \n",
    "                                \n",
    "                                Solve the queries STEP by STEP and feel free to use the tools available to you and do not hallucinate or make assumptions.\n",
    "                                \"\"\"\n",
    "        self.agent = self.get_agent()\n",
    "\n",
    "    def get_agent(self):\n",
    "        agent = FunctionCallingAgent.from_tools([multiply_tool, add_tool,\n",
    "                                                 real_number_tool],\n",
    "                                        llm=self.llm,verbose=True,\n",
    "                                        system_prompt=self.system_prompt)\n",
    "        return agent\n",
    "    \n",
    "    def chat(self, query: str):\n",
    "        response_obj = self.agent.chat(query)\n",
    "        return response_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step d363ed0f-4698-4837-92cc-f901f9a37b4f. Step input: what is 2+2\n",
      "Added user message to memory: what is 2+2\n",
      "=== Calling Function ===\n",
      "Calling function: add with args: {\"a\": 2, \"b\": 2}\n",
      "=== Function Output ===\n",
      "4.0\n",
      "> Running step 88146b13-79f2-4a97-9f9a-b22ab7ba2b3e. Step input: None\n",
      "=== LLM Response ===\n",
      "Answer: 4.0\n",
      "Tool Used: add\n",
      "Reasoning: The tool was used to calculate the sum of two numbers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentChatResponse(response='Answer: 4.0\\nTool Used: add\\nReasoning: The tool was used to calculate the sum of two numbers.', sources=[ToolOutput(content='4.0', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 2, 'b': 2}}, raw_output=4.0, is_error=False)], source_nodes=[], is_dummy_stream=False, metadata=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = AgentController()\n",
    "query = \"what is 2+2\"\n",
    "agent.chat(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
